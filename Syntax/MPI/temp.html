<h1 id="mpi-introduction">MPI Introduction</h1>
<p>It is a parallel programming methodology wherein the architecture for cores and memory are required to be distributed. MPI works on shared memory systems also. But it cannot take advantage of the shared memory processes when invoked.</p>
<p>The process is as follows. The program execution is such that all the processes will be running the same program but having different set of data. Information is passed between threads via messages to inform the status. So, it follows SPMD or single program multiple data approach. Data to be shared between threads are explicitly passed between threads via messages.</p>
<p>Sources:</p>
<ol type="1">
<li>High Performance Computing - Prof. Randall J LeVeque, University of Washington, Coursera Course.</li>
<li>Sharcnet YouTube channel tutorials</li>
</ol>
<p>GNU Fortran will have an MPI. MPICH is recommended to be installed and used.</p>
<p>Like fortran, all the variables and subroutines are CASE INSENSITIVE, EVEN IN MPI routines.</p>
<h2 id="variables-and-terms">Variables and Terms</h2>
<p><strong>Communicator</strong>:</p>
<p>Only a group of processors communicate. Processors communicate on a purpose/context. A communicator is a variable/() used for communicating messages or data between processors on a context.</p>
<p><code>MPI_COMM_WORLD</code> is a default communicator to communicate to all the processes and processors.</p>
<p><code>MPI_COMM_RANK(comm1, proc_num, ierr)</code> returns the rank/number/position/label of the processor in the communicator group. The value is given to proc-num</p>
<p><code>MPI_COMM_SIZE(comm1, num_proc, ierr)</code> returns the number of processors/processes in the communicator group. The value is given to num_proc</p>
<p><code>ierr</code> is a logical variable to indicate any error. If ierr is zero, then no error. If it is non-zero, then an MPI error is present.</p>
<p><code>MPI_INIT(ierr)</code> is used for initializing an MPI process.</p>
<p><code>MPI_FINALIZE(ierr)</code> is used for ending an MPI process.</p>
<p>There are 125+ MPI functions. Some important and main functions other than the above mentioned ones are as follows. They are helpful to do a wide variety of programs.</p>
<ol type="1">
<li><code>MPI_INTEGER</code>: Used to specify the type of data being sent</li>
<li><code>MPI_SUM</code>: Used for doing sum reduction operation</li>
<li><code>MPI_SEND</code>: Used to send a message</li>
<li><code>MPI_RCV</code>: Used to receive a message</li>
<li><code>MPI_BCAST</code>: Used to broadcast a message to all processors</li>
<li><code>MPI_REDUCE</code>: Used to do a reduction process</li>
</ol>
<h2 id="sample-hello-world-program-in-fortran">Sample Hello World Program in Fortran</h2>
<div class="highlight"><pre><span></span><span class="c">! A sample hello world program in Fortran MPI</span>

<span class="k">program </span><span class="n">hello_mpi</span>

    <span class="k">use </span><span class="n">mpi</span>
    <span class="k">implicit none</span>
<span class="k">    </span><span class="kt">integer </span><span class="n">ierr</span><span class="p">,</span> <span class="n">pro_num</span><span class="p">,</span> <span class="n">no_pro</span>

    <span class="c">! use mpi is used for invoking the MPI subroutines</span>
    <span class="c">! ierr is an error indicator in MPI processes.</span>
    <span class="c">! ierr is to be zero. If non-zero, then there is an error.</span>
    <span class="c">! pro_num is the processor number</span>
    <span class="c">! no_pro is the number of processors</span>

    <span class="k">call </span><span class="n">MPI_INIT</span><span class="p">(</span><span class="n">ierr</span><span class="p">)</span>
    <span class="c">! mpi_init starts the MPI processes</span>
    
    <span class="k">call </span><span class="n">MPI_COMM_SIZE</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">no_pro</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
    <span class="c">! mpi_comm_size finds the number of processes under use</span>
    
    <span class="k">call </span><span class="n">MPI_COMM_RANK</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">pro_num</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
    <span class="c">! mpi_comm_rank finds the processor number</span>
    <span class="c">! MPI_COMM_WORLD is a default communicator used for </span>
    <span class="c">! communicating info to all processors</span>

    <span class="c">!print *, &quot;ierr value is:&quot;, ierr</span>
    <span class="c">!print *, &quot;MPI_COMM_WORLD value is:&quot;, MPI_COMM_WORLD</span>
    <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s2">&quot;Hello world from processor number&quot;</span><span class="p">,</span> <span class="n">pro_num</span><span class="p">,</span> <span class="s2">&quot;of&quot;</span><span class="p">,</span> <span class="n">no_pro</span><span class="p">,</span> <span class="s2">&quot;Processors&quot;</span>

    <span class="k">call </span><span class="n">MPI_FINALIZE</span><span class="p">(</span><span class="n">ierr</span><span class="p">)</span>
    <span class="c">! mpi_finalize ends the MPI processes</span>

<span class="k">end program </span><span class="n">hello_mpi</span>
</pre></div>

<p>To compile and create the executable, use</p>
<div class="highlight"><pre><span></span>mpif90 filename.f90
</pre></div>

<p>If MPICH is used, use</p>
<div class="highlight"><pre><span></span>mpif90.mpich filename.f90 or mpif90 filename.f90 or .*.f95
</pre></div>

<p>To execute the file, use</p>
<div class="highlight"><pre><span></span>mpiexec -n <span class="m">4</span> ./a.out 
!mpiexec helps to indicate the number of processors to be used.
</pre></div>

<p>Where -n stands for the number of processors to be used. 4 processors are used here. If more processors are indicated than what is available, then it wont show an error. Each processor will do two or more processes to meet the number indicated and thus, it won’t be parallel. This is recommended when for debugging.</p>
<h2 id="creating-communicators">Creating Communicators</h2>
<p><code>MPI_COMM_WORLD</code> is a communicator for all the processors.</p>
<p>If a subset of processors were to be used, then a new communicator has to be created and used.</p>
<h2 id="mpi_bcast">MPI_BCAST</h2>
<div class="highlight"><pre><span></span><span class="k">call </span><span class="n">MPI_BCAST</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">count</span><span class="p">,</span> <span class="n">datatype</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
</pre></div>

<p>This statement broadcasts variables from one processor thread to all the others.</p>
<p><strong>start</strong> : the memory address or variable name or an array entry.</p>
<p><strong>count</strong> : number of variables/data to be sent using the entry in start.</p>
<p><strong>datatype</strong> : the data type of the value(s) in the start.</p>
<p><strong>root</strong> : the processor number that sends this variable to all the threads or the process doing the broadcast.</p>
<p><strong>comm</strong> : communicator under use.</p>
<p><strong>ierr</strong> : the error variable.</p>
<p>eg: to broad cast a double precision variable, x, from processor 3, to all the processes, then</p>
<div class="highlight"><pre><span></span><span class="n">MPI_BCAST</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
</pre></div>

<p>For passing array values, it is a bit tricky. A new memory continuous array has to be made and then this array has to be made use for broadcast, or using a loop, the values can be made use for broadcast.</p>
<p>eg: you want to pass the jth column of a matrix/array having nrows and ncols, then the command will be</p>
<div class="highlight"><pre><span></span><span class="n">MPI_BCAST</span><span class="p">(</span><span class="n">a</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">j</span><span class="p">),</span><span class="n">nrows</span><span class="p">,</span><span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="n">ierr</span><span class="p">)</span>
</pre></div>

<p>where <code>a(1,j)</code> is the starting address of the jth column and nrows of elements are there continuously in the memory allocation. This works for passing columns in Fortran because Fortran is column based in memory allocation. This works for passing rows in C.</p>
<p>For passing rows/columns of an array that are not memory contiguous in Fortran/C, a buffer variable is to be created and it has to be allocated with the elements of the row/column using a loop and broadcasted.</p>
<p><code>MPI_VECTOR</code> is a simple way to do this process.</p>
<h2 id="mpi_send-mpi_recv">MPI_SEND MPI_RECV</h2>
<p><strong>MPI_SEND</strong> and <strong>MPI_RECV</strong> are used for sending and receiving particular parts of data to and from other processes.</p>
<p><code>MPI_SEND</code> is used for sending data from one process to another</p>
<p><code>MPI_RECV</code> is used for receiving the data from the <code>MPI_SEND</code> call.</p>
<p>While sending and receiving multiple data between processes , to ensure the correct data is sent and received (simply to check the match) all around, an identifier is needed. This identifier is called a tag. <code>MPI_SEND</code> will be read by the MPI_RECV command having the same tag.</p>
<p>Tag is usually an integer, but can be used as a meaningful info, like row/column number.</p>
<div class="highlight"><pre><span></span><span class="k">call </span><span class="n">MPI_SEND</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">count</span><span class="p">,</span> <span class="n">datatype</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
</pre></div>

<p><strong>start</strong> = Starting address or the variable name or the array element</p>
<p><strong>count</strong> = No. of variables in continuous order to send</p>
<p><strong>datatype</strong> = type of each element (int, float etc.,)</p>
<p><strong>dest</strong> = destination process</p>
<p><strong>tag</strong> = identifier tag (0 to 32767)</p>
<p><strong>comm</strong> = communicator</p>
<p><strong>ierr</strong> = error variable</p>
<div class="highlight"><pre><span></span><span class="k">call </span><span class="n">MPI_RECV</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="nb">count</span><span class="p">,</span> <span class="n">datatype</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
</pre></div>

<p><strong>start</strong> = Starting address or the variable name or the array element</p>
<p><strong>count</strong> = No. of variables in continuous order to send</p>
<p><strong>datatype</strong> = type of each element (int, float etc.,)</p>
<p><strong>source</strong> = process from where data is coming</p>
<p><strong>tag</strong> = identifier tag (0 to 32767)</p>
<p><strong>comm</strong> = communicator</p>
<p><strong>status</strong> = integer array of length MPI_STATUS_SIZE. Has a lot of uses.</p>
<p>status array/vector has an inbuilt size namely <strong>MPI_STATUS_SIZE</strong>.</p>
<p>status array has to be defined explicitly as:</p>
<div class="highlight"><pre><span></span>    <span class="kt">integer</span><span class="p">,</span> <span class="k">dimension</span><span class="p">(</span><span class="n">MPI_STATUS_SIZE</span><span class="p">)</span> <span class="kd">::</span> <span class="n">status</span>
</pre></div>

<p><code>ierr</code> = error variable</p>
<p>A source can match any source with the keyword <strong>MPI_ANY_SOURCE</strong></p>
<p>A tag can match any tag with the keyword <strong>MPI_ANY_TAG</strong></p>
<p>eg:</p>
<div class="highlight"><pre><span></span><span class="k">if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">==</span> <span class="mi">4</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    </span><span class="n">i</span> <span class="o">=</span> <span class="mi">55</span>
    <span class="k">call </span><span class="n">MPI_SEND</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INTEGER</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
<span class="k">end if</span>
<span class="k">if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    call </span><span class="n">MPI_RECV</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INTEGER</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
    <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s2">&quot;j = &quot;</span><span class="p">,</span><span class="n">j</span>  <span class="c">! Process 3 Will print j = 55</span>
<span class="k">end if</span>
</pre></div>

<p>In this example, i is sent from process number 4 and received by process number 3 as j. The Tag is 21. The receive call will not accept messages from other sent calls.</p>
<p>This is a <strong>blocking MPI_RECV</strong>. This subroutine will not return or complete its job until it receives a call from MPI_SEND with the tag 21. So, the next statement will not run unless it is finished called. Similarly, it will wait till all the other processes are done that calls and sends a message to it. Can lead to code hangups if not done properly.</p>
<p>eg:</p>
<div class="highlight"><pre><span></span><span class="c">!This piece of code will pass value of i from process 0 to 1 to 2 to ... to num_proc - 1</span>

<span class="k">if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    </span><span class="n">i</span> <span class="o">=</span> <span class="mi">55</span>
    <span class="k">call </span><span class="n">MPI_SEND</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INTEGER</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>

<span class="k">else if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">&lt;</span> <span class="n">num_procs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    call </span><span class="n">MPI_RECV</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INTEGER</span><span class="p">,</span> <span class="n">proc_num</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>

     <span class="k">call </span><span class="n">MPI_SEND</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INTEGER</span><span class="p">,</span> <span class="n">proc_num</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>

<span class="k">else if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">==</span> <span class="n">num_procs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    call </span><span class="n">MPI_RECV</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_INTEGER</span><span class="p">,</span> <span class="n">proc_num</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
    <span class="k">print</span> <span class="o">*</span><span class="p">,</span> <span class="s2">&quot;i = &quot;</span><span class="p">,</span><span class="n">i</span>  <span class="c">! Process proc_num-1 Will print i = 55</span>
<span class="k">end if</span>
</pre></div>

<h2 id="status-and-tags-in-mpi_recv">Status and Tags in MPI_RECV</h2>
<p><code>Status</code> is a parameter in <code>MPI_RECV</code>.</p>
<p>Used for knowing from where the data was received from and what data is received. Especially when <code>MPI_ANY_SOURCE</code> or <code>MPI_ANY_TAG</code> are used.</p>
<p>Status is an array of integers. It has one element indexed with the keyword <code>MPI_SOURCE</code>. Denoted as status (<code>MPI_SOURCE</code>). This will return a number from which the source of the message can be found.</p>
<p>Using this, we can find if <code>MPI_ANY_SOURCE</code> was used or not.</p>
<p>Similarly, <code>status(MPI_TAG)</code> will return the tag of the source message. Using this, we can find if MPI_ANY_TAG was used or not.</p>
<p>eg:</p>
<div class="highlight"><pre><span></span><span class="c">! Master processor 0 sends the jth column of an array to the jth </span>
<span class="c">! worker and gets the 1-norm to store in anorm(j) j = 1, 2, 3, ..., ncols</span>

<span class="c">! code for master processor = 0</span>
<span class="k">if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">then</span>
<span class="k">    do </span><span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span>
          <span class="k">call </span><span class="n">MPI_SEND</span><span class="p">(</span><span class="n">a</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>
    <span class="k">end do</span>

<span class="k">    do </span><span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span>
          <span class="k">call </span><span class="n">MPI_RECV</span><span class="p">(</span><span class="n">colnorm</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span> <span class="n">MPI_ANY_SOURCE</span><span class="p">,</span> <span class="n">MPI_ANY_TAG</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>

          <span class="n">jj</span> <span class="o">=</span> <span class="n">status</span><span class="p">(</span><span class="n">MPI_TAG</span><span class="p">)</span>
          <span class="n">anorm</span><span class="p">(</span><span class="n">jj</span><span class="p">)</span> <span class="o">=</span> <span class="n">colnorm</span>
    <span class="k">end do</span>
<span class="k">end if</span>
</pre></div>

<p>Explanation: The master processor will make n send calls. Each call will pass the jth column fully. a(1,j) is the beginning address of the column j. nrows indicate the n consecutive values in the array. The source is j itself. J denotes both the processor under consideration and the iteration number. The tag is again j. So, for each column sent, the tag used is the column number itself.</p>
<p>In the second do loop, the master processor gets n receive calls. These calls will be in any order. They will receive the column norm from other processes in any order. The code for slave processors does the column norm calculation. So, instead of waiting to receive the message in a regular order, the keyword MPI_ANY_SOURCE ensures that any of the finished processors can send the data to be received by processor 0. To ensure the same, the keyword MPI_ANY_TAG does the same. It assists any finished processor to come accordingly. Note that for a particular SOURCE, the corresponding TAG alone will be received. No mix and match.</p>
<p>But, to know which TAG has popped up or been received, the MPI_TAG element in status has the memory of the TAG received. So, this will say the column norm of which column was calculated and returned. jj gets the tag received and using that, the array anorm is filled with the column norm pertaining to the column, tag and source j.</p>
<p>The code that does the column norm calculation is given below.</p>
<div class="highlight"><pre><span></span><span class="c">! code for the slave processors</span>
<span class="k">if</span> <span class="p">(</span><span class="n">proc_num</span> <span class="o">/=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">then</span>

<span class="k">     call </span><span class="n">MPI_RECV</span><span class="p">(</span><span class="n">colvect</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MPI_ANY_TAG</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>

     <span class="n">j</span> <span class="o">=</span> <span class="n">status</span><span class="p">(</span><span class="n">MPI_TAG</span><span class="p">)</span>
    <span class="n">colnorm</span> <span class="o">=</span> <span class="mf">0.d0</span>
    <span class="k">do </span><span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nrows</span>
          <span class="n">colnorm</span> <span class="o">=</span> <span class="n">colnorm</span> <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">colvect</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="k">end do</span>

<span class="k">    call </span><span class="n">MPI_SEND</span><span class="p">(</span><span class="n">colnorm</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">MPI_DOUBLE_PRECISION</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="n">ierr</span><span class="p">)</span>

<span class="k">end if</span>
</pre></div>

<p>The <code>MPI_RECV</code> call receives each call from the master processor n times. Each call is received by one slave processor. To ensure that the call can be received in any order, <code>MPI_ANY_TAG</code> are used.</p>
<p><code>j = status(MPI_TAG)</code> gets the tag and the column number under consideration from the sent message. The do loop calculates the column norm and the result colnorn is sent by each of the n processors once through the <code>MPI_SEND</code> call. When sent, the source is made as 0 and the tag is sent as j, to indicate that the values are going to process 0 and the value corresponds to the column j.</p>
<h2 id="mpi_abort">MPI_ABORT</h2>
<p>To terminate or abort a program abruptly or in case of any error condition, use the <strong>MPI_ABORT</strong> call.</p>
<div class="highlight"><pre><span></span>    <span class="k">call </span><span class="n">MPI_ABORT</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>

<p>1 is the error value</p>
